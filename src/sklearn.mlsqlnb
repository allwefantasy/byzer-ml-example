[{"kind":1,"language":"markdown","value":"# Sklearn Exmaple\n\nIn this notebook, we will show you how to:\n\n1. train sklearn model in Byzer \n2. deploy the model as UDF in Byzer","outputs":[]},{"kind":1,"language":"markdown","value":"## Prepare Data","outputs":[]},{"kind":2,"language":"mlsql","value":"load csv.`./example-data/iris.csv` where header = \"true\"\nand inferSchema = \"true\" \nas iris;","outputs":[{"mime":"x-application/mlsql-notebook","value":"{\n\t\"schema\": {\n\t\t\"type\": \"struct\",\n\t\t\"fields\": [\n\t\t\t{\n\t\t\t\t\"name\": \"sepal_length\",\n\t\t\t\t\"type\": \"double\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"sepal_width\",\n\t\t\t\t\"type\": \"double\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"petal_length\",\n\t\t\t\t\"type\": \"double\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"petal_width\",\n\t\t\t\t\"type\": \"double\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"species\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"species_id\",\n\t\t\t\t\"type\": \"integer\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t}\n\t\t]\n\t},\n\t\"data\": [\n\t\t{\n\t\t\t\"sepal_length\": 5.1,\n\t\t\t\"sepal_width\": 3.5,\n\t\t\t\"petal_length\": 1.4,\n\t\t\t\"petal_width\": 0.2,\n\t\t\t\"species\": \"setosa\",\n\t\t\t\"species_id\": 1\n\t\t},\n\t\t{\n\t\t\t\"sepal_length\": 4.9,\n\t\t\t\"sepal_width\": 3,\n\t\t\t\"petal_length\": 1.4,\n\t\t\t\"petal_width\": 0.2,\n\t\t\t\"species\": \"setosa\",\n\t\t\t\"species_id\": 1\n\t\t},\n\t\t{\n\t\t\t\"sepal_length\": 4.7,\n\t\t\t\"sepal_width\": 3.2,\n\t\t\t\"petal_length\": 1.3,\n\t\t\t\"petal_width\": 0.2,\n\t\t\t\"species\": \"setosa\",\n\t\t\t\"species_id\": 1\n\t\t},\n\t\t{\n\t\t\t\"sepal_length\": 4.6,\n\t\t\t\"sepal_width\": 3.1,\n\t\t\t\"petal_length\": 1.5,\n\t\t\t\"petal_width\": 0.2,\n\t\t\t\"species\": \"setosa\",\n\t\t\t\"species_id\": 1\n\t\t},\n\t\t{\n\t\t\t\"sepal_length\": 5,\n\t\t\t\"sepal_width\": 3.6,\n\t\t\t\"petal_length\": 1.4,\n\t\t\t\"petal_width\": 0.2,\n\t\t\t\"species\": \"setosa\",\n\t\t\t\"species_id\": 1\n\t\t}\n\t]\n}"}]},{"kind":1,"language":"markdown","value":"## Train sklearn model\n\nIn this section, we will use iris table loaded from csv file to train a sklearn model to predict the species of iris with the support\nof Byzer-python.\n\n> Note: Byzer-python is a distributed python environment based on Ray in Byzer, which is desighed to leverage the power of Python ecosystem.\n\nBefore we start, we need to install [Miniconda](https://docs.conda.io/en/latest/miniconda.html) first, and then restore the python environment with the following command:\n\n> Note: you should modify the `prefix` in  environment-*.yml to your own conda environment path.\n\n\n```bash\nconda env create --file environment.yml\n```\n\nAfter the environment is restored, you will get a conda environment named `ray-2.3.0` with all the dependencies installed.\n\n","outputs":[]},{"kind":2,"language":"python","value":"#%python\n#%input=iris\n#%output=iris_model\n#%schema=file\n#%runIn=driver\n#%dataMode=model\n#%cache=true\n#%pythonExec=/opt/miniconda3/envs/ray-2.3.0/bin/python\n\nfrom pyjava.api.mlsql import RayContext,PythonContext\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport joblib\nfrom pyjava.storage import streaming_tar\nimport os\n\nray_context = RayContext.connect(globals(),None)\ndata = ray_context.to_pandas()\n\ntrain,test = train_test_split(data, test_size = 0.4, stratify = data['species_id'], random_state = 42)\n\nX_train = train[['sepal_length','sepal_width','petal_length','petal_width']]\ny_train = train.species_id\nX_test = test[['sepal_length','sepal_width','petal_length','petal_width']]\ny_test = test.species_id\n\nmod_dt = DecisionTreeClassifier(max_depth = 3, random_state = 1)\nmod_dt.fit(X_train.values,y_train.values)\nprediction=mod_dt.predict(X_test.values)\nprint('The accuracy of the Decision Tree is',\"{:.3f}\".format(metrics.accuracy_score(prediction,y_test)))\n\nmodel_path = \"/tmp/model\"\n\nif not os.path.exists(model_path):\n    os.makedirs(model_path, exist_ok=True)\n    \njoblib.dump(mod_dt,os.path.join(model_path,\"iris_model\") )\n\nmodel_binary = streaming_tar.build_rows_from_file(model_path)\n\nray_context.build_result(model_binary)","outputs":[{"mime":"x-application/mlsql-notebook","value":"{\n\t\"schema\": {\n\t\t\"type\": \"struct\",\n\t\t\"fields\": [\n\t\t\t{\n\t\t\t\t\"name\": \"files\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t}\n\t\t]\n\t},\n\t\"data\": [\n\t\t{\n\t\t\t\"files\": \"././@PaxHeader\"\n\t\t},\n\t\t{\n\t\t\t\"files\": \"iris_model\"\n\t\t}\n\t]\n}"}]},{"kind":1,"language":"markdown","value":"## Save Model\n\nIn this section, we will save the trained model to a delta lake. \nThis means the data and model are stored in the same place, which is convenient for model management.\n\nBy default, the delta lake is stored in `data` which is under the current project directory. You can change the path in `.mlsql.config` with the following configuration:\n\n```json\nengine.streaming.datalake.path= YOUR LOCAL PATH\n```\n","outputs":[]},{"kind":2,"language":"mlsql","value":"save overwrite iris_model as delta.`ai.iris_model`;","outputs":[{"mime":"x-application/mlsql-notebook","value":"{\n\t\"schema\": {\n\t\t\"type\": \"struct\",\n\t\t\"fields\": [\n\t\t\t{\n\t\t\t\t\"name\": \"owner\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"jobType\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"jobName\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"jobContent\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"groupId\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"progress\",\n\t\t\t\t\"type\": {\n\t\t\t\t\t\"type\": \"struct\",\n\t\t\t\t\t\"fields\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"name\": \"totalJob\",\n\t\t\t\t\t\t\t\"type\": \"long\",\n\t\t\t\t\t\t\t\"nullable\": false,\n\t\t\t\t\t\t\t\"metadata\": {}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"name\": \"currentJobIndex\",\n\t\t\t\t\t\t\t\"type\": \"long\",\n\t\t\t\t\t\t\t\"nullable\": false,\n\t\t\t\t\t\t\t\"metadata\": {}\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"name\": \"script\",\n\t\t\t\t\t\t\t\"type\": \"string\",\n\t\t\t\t\t\t\t\"nullable\": true,\n\t\t\t\t\t\t\t\"metadata\": {}\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"startTime\",\n\t\t\t\t\"type\": \"long\",\n\t\t\t\t\"nullable\": false,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"timeout\",\n\t\t\t\t\"type\": \"long\",\n\t\t\t\t\"nullable\": false,\n\t\t\t\t\"metadata\": {}\n\t\t\t}\n\t\t]\n\t},\n\t\"data\": [\n\t\t{\n\t\t\t\"owner\": \"admin\",\n\t\t\t\"jobType\": \"script\",\n\t\t\t\"jobName\": \"3b738ea1-8d33-4907-94fb-621c60778432\",\n\t\t\t\"jobContent\": \"save overwrite iris_model as delta.`ai.iris_model`;\",\n\t\t\t\"groupId\": \"a25514a5-2492-4578-933d-d5d5e2dcdc4c\",\n\t\t\t\"progress\": {\n\t\t\t\t\"totalJob\": 1,\n\t\t\t\t\"currentJobIndex\": 1,\n\t\t\t\t\"script\": \"save overwrite iris_model as delta.`ai.iris_model`\"\n\t\t\t},\n\t\t\t\"startTime\": 1678275853370,\n\t\t\t\"timeout\": -1\n\t\t}\n\t]\n}"}]},{"kind":1,"language":"markdown","value":"## Load Model","outputs":[]},{"kind":2,"language":"mlsql","value":"load delta.`ai.iris_model` as iris_model;","outputs":[]},{"kind":1,"language":"markdown","value":"## Deploy Model as UDF\n\nByzer supports to deploy the model as UDF, which means you can use the model in SQL directly.\n\nNotice that this ability is based on Ray. So you need to start Ray cluster first.\n\n```bash\nconda activate ray-2.3.0\nray start --head --port 6380\n```\n\nInorder to finish our job, There are two python functions are needed:\n\n1. init_sklearn, this function defines how to convert the binary file to a model\n2. predict_func, this is a callback function , when UDF iris_model_predict is called, then the system will invoke this function.\n\n`init_sklearn`, `predict_func` are both automatically dilevered to Ray cluster when the register statement is executed.\n\n\nThe `predict_func` has two parameters:\n\n1. model, the model object loaded from init_sklearn\n2. v, the feature we need to predict. the v type is: list[list[double]], this type means batch of features.\nThe return value is also should like this type: {“value”:list[list[double]]}. The key is fixed and the value is batch of predicted items.\n\n\n","outputs":[]},{"kind":2,"language":"mlsql","value":"!python conf \"rayAddress=127.0.0.1:10001\";\n!python conf \"schema=file\";\n!python env \"PYTHON_ENV=source /opt/miniconda3/bin/activate ray-2.3.0 && export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\";\n!python conf \"dataMode=model\";\n!python conf \"runIn=driver\";\n\nregister Ray.`iris_model` as iris_model_predict where \nmaxConcurrency=\"2\"\nand debugMode=\"true\"\nand registerCode='''\n\nimport ray\nimport numpy as np\nfrom pyjava.api.mlsql import RayContext\nfrom pyjava.udf import UDFMaster,UDFWorker,UDFBuilder,UDFBuildInFunc\n\nfrom typing import Any, NoReturn, Callable, Dict, List\nimport time\nfrom ray.util.client.common import ClientActorHandle, ClientObjectRef\n\nfrom pyjava.storage import streaming_tar\nimport uuid\n\nimport joblib\nimport os\n\n\nray_context = RayContext.connect(globals(), context.conf[\"rayAddress\"])\n\ndef init_sklearn(model_refs: List[ClientObjectRef], conf: Dict[str, str]) -> Any:\n    model_path = \"/tmp/model/{}\".format(str(uuid.uuid4()))\n    streaming_tar.save_rows_as_file((ray.get(ref) for ref in model_refs), model_path)\n    return joblib.load(os.path.join(model_path,\"iris_model\"))\n\ndef predict_func(model,v):\n    prediction=model.predict(v)\n    return {\"value\":[[float(item) for item in prediction]]}\n\n\nUDFBuilder.build(ray_context,init_sklearn,predict_func)\n\n'''\n;","outputs":[{"mime":"x-application/mlsql-notebook","value":"{\n\t\"schema\": {\n\t\t\"type\": \"struct\",\n\t\t\"fields\": [\n\t\t\t{\n\t\t\t\t\"name\": \"key\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t},\n\t\t\t{\n\t\t\t\t\"name\": \"value\",\n\t\t\t\t\"type\": \"string\",\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t}\n\t\t]\n\t},\n\t\"data\": []\n}"}]},{"kind":1,"language":"markdown","value":"## Predict with UDF","outputs":[]},{"kind":2,"language":"mlsql","value":"select array(sepal_length,sepal_width,petal_length,petal_width) as feature from iris  as testTable;\n\nselect iris_model_predict(array(feature)) as predicted from testTable as output;","outputs":[{"mime":"x-application/mlsql-notebook","value":"{\n\t\"schema\": {\n\t\t\"type\": \"struct\",\n\t\t\"fields\": [\n\t\t\t{\n\t\t\t\t\"name\": \"predicted\",\n\t\t\t\t\"type\": {\n\t\t\t\t\t\"type\": \"array\",\n\t\t\t\t\t\"elementType\": {\n\t\t\t\t\t\t\"type\": \"array\",\n\t\t\t\t\t\t\"elementType\": \"double\",\n\t\t\t\t\t\t\"containsNull\": false\n\t\t\t\t\t},\n\t\t\t\t\t\"containsNull\": true\n\t\t\t\t},\n\t\t\t\t\"nullable\": true,\n\t\t\t\t\"metadata\": {}\n\t\t\t}\n\t\t]\n\t},\n\t\"data\": [\n\t\t{\n\t\t\t\"predicted\": [\n\t\t\t\t[\n\t\t\t\t\t1\n\t\t\t\t]\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"predicted\": [\n\t\t\t\t[\n\t\t\t\t\t1\n\t\t\t\t]\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"predicted\": [\n\t\t\t\t[\n\t\t\t\t\t1\n\t\t\t\t]\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"predicted\": [\n\t\t\t\t[\n\t\t\t\t\t1\n\t\t\t\t]\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"predicted\": [\n\t\t\t\t[\n\t\t\t\t\t1\n\t\t\t\t]\n\t\t\t]\n\t\t}\n\t]\n}"}]}]